text          | 06 ALH 049944 (to/d)
              | 3/2/05
              | 2:06 pm
              | Page 60
              | active learning
              | in higher education
              | Copyright © 2005 The Higher
              | Education Academy and
              | SAGE Publications (London,
              | Thousand Oaks, CA and
              | New Delhi)
              | Vol 6(1): 60–72
              | DOI: 10.1177/1469787405049944
              | ARTICLE
              | From evaluation
              | towards an
              | agenda for
              | quality
              | improvement
              | The development and application of the
              | Template Process
              | M A R K N . K . S A U N D E R S
              | Oxford Brookes University, UK
              | C H R I S T I N E S . W I L L I A M S
              | University of Gloucestershire, UK
              | A B S T R AC T For many students and lecturers evaluation is conﬁned to
              | some form of survey. Whilst these can provide useful feedback, their
              | focus is likely to reﬂect the values and norms of those commissioning
              | and undertaking the evaluation. For real improvements in quality to
              | occur both lecturers’ and students’ perspectives of factors that are
              | important need to be made explicit and understood. Drawing upon
              | literature relating to service quality and in particular the Service
              | Template, this article outlines and evaluates an alternative approach for
              | establishing students’ and lecturers’ perspectives, obtaining feedback
              | and developing an agenda for improvement. Using the example of
              | dissertation supervision, it is argued that a revised Template Process
              | operating within a process consultation framework can meet these
              | concerns. The article concludes with a discussion of the applicability
              | of the Template Process to evaluating teaching and learning.
              | K E Y WO R D S : e va l u a t i o n , p r o c e s s c o n s u l t a t i o n , q u a l i t y, s t u d e n t s
              | a n d l e c t u r e r s, Te m p l a t e P r o c e s s
              | Introduction
              | Student involvement in evaluation of modules is well recognized as a
              | cornerstone of quality improvement in higher education (Hendry et al.,
              | 2001). However, despite the attention devoted to evaluation and review, for
              | many students and lecturers the process of feedback is conﬁned to some
              | form of survey designed to assess a range of pre-determined constructs and
meta          | 60
text          | 06 ALH 049944 (to/d) 3/2/05 2:06 pm Page 61
              | S AU N D E R S & W I L L I A M S : A N A G E N D A F O R Q U A L I T Y I M P R OV E M E N T
              | administered at the end of a module. Whilst such surveys can provide useful
              | feedback to lecturers, this raises a number of issues. These relate to the focus
              | of data collection, and in particular the extent to which questions asked
              | reﬂect the norms and values of both students and lecturers (Harvey, 1998),
              | the low response rate to such surveys and the commitment of lecturers to
              | use the ﬁndings to improve quality and the learning experience for students
              | (Bingham and Ottewill, 2001).
              | Research exploring the quality review process has included work
              | drawing upon the service quality literature, arguing that provision of higher
              | education programmes can be equated to the provision of a service
              | (Cuthbert, 1996). Whilst acknowledging that equating students to
              | customers is open to debate, it can be argued that, by engaging in higher
              | education, students are participating in and paying for a service. Conse-
              | quently, evaluation and review of quality should reﬂect the dyadic nature
              | of such service-type relationships (Rosen and Suprenant, 1998) incorpo-
              | rating the views of both students as users and lecturers as deliverers. It
              | therefore follows that, if meaningful improvements are to occur, both
              | students’ and lecturers’ perspectives on those factors that are important and
              | their views on the quality of each need to be made explicit. These poten-
              | tially differing perspectives need to be understood by lecturers if they are
              | to go beyond addressing surface concerns relating to quality of learning.
              | In this article, we draw upon developments in service quality to propose
              | an alternative approach to evaluation of the student experience. Following
              | an overview of traditional measures of service quality and their short-
              | comings in relation to evaluation and review, Staughton and Williams’
              | (1994) Service Template is evaluated as an alternative. Drawing upon this,
              | developments to the process are described, which allow the views of
              | students and lecturers to be captured separately and enable them to be
              | explored and understood, prior to developing an agenda for action. The
              | application of this process is illustrated, using a case study of the super-
              | vision of undergraduate dissertations at a new university business school.
              | We conclude with a discussion of merits and shortcomings of the process.
              | Measuring quality
              | Within service quality literature, the most widely used and debated tool is
              | SERVQUAL, a generic instrument developed to measure service quality
              | (Parasuraman et al., 1991). This instrument and its derivatives have focused
              | on measurement of the gap between service users’ perceptions and expec-
              | tations across a series of constructs that characterize a service. Notwith-
              | standing shortcomings of conceptualizing service quality in this manner,
              | recognized in the SERVQUAL debates (for example Carmen, 1990; Cronin
meta          | 61
text          | 06 ALH 049944 (to/d) 3/2/05 2:06 pm Page 62
              | A C T I V E L E A R N I N G I N H I G H E R E D U C A T I O N 6(1)
              | and Taylor, 1992), the use of a disconﬁrmation approach to highlight ‘gaps’
              | between perceptions and expectations and indicate possible areas for
              | improvement is reported widely in the literature (for example: Parasuraman,
              | 1995; Cuthbert, 1996; Narasimhan, 1997). Constructs where service users’
              | perceptions do not meet expectations suggest areas for improvement.
              | Constructs where users’ perceptions equal or exceed expectations imply that
              | there is no requirement for improvement, or that more may be being done
              | than necessary. However, implicit within this is an assumption that data
              | collected against generic dimensions can capture what is important about a
              | particular service.
              | Research by Carmen (1990) highlights that the constructs used to char-
              | acterize service quality are likely to be speciﬁc to a service and the industry
              | within which it is located, a view echoed in respect of higher education
              | (for example Cuthbert, 1996; Narasimhan, 1997). They and others argue
              | that the use of generic constructs to measure service quality does not
              | provide the details necessary to assess the quality of higher education
              | relationships. Such relationships are considered more complex than those
              | of other services such as a shop or restaurant. For example, they are more
              | intense, last longer and contain considerable variety at both course and
              | module levels. In addition, generic constructs may fail to capture the
              | uniqueness of speciﬁc modules and be understood and interpreted differ-
              | ently by students and lecturers.
              | Traditional approaches such as questionnaires can, with careful design,
              | minimize shortcomings associated with generic constructs and be used to
              | explore gaps between perceptions and expectations. However, these often
              | reﬂect the values, assumptions and issues that are important to their design-
              | ers, which may not correspond to those of the students (Chapple and
              | Murphy, 1996). Alternatively, standardized questionnaires make assump-
              | tions about the appropriateness of generic constructs across a range of
              | different teaching and learning experiences (Narasimhan, 1997). Further-
              | more, the data collected may not provide clear indications of the action
              | necessary to improve quality (Hendry et al., 2001).
              | The approaches outlined so far typically assess quality from only the
              | students’ perspective, failing to acknowledge the value of the lecturer’s
              | perspective in a dyadic service-type relationship. The logic underpinning
              | the ‘gaps’ model (Parasuraman et al., 1985) provides further support for
              | such an approach, as there may well be differences in that which is
              | considered important by students and lecturers and their perceptions and
              | expectations. Problems of second order interpretation can occur when data
              | collected are subject to interpretation by a third party as part of review
              | process, raising doubts about the validity and completeness of such data. A
              | lecturer undertaking a module evaluation may have ﬁltered and added her
meta          | 62
text          | 06 ALH 049944 (to/d) 3/2/05 2:06 pm Page 63
              | S AU N D E R S & W I L L I A M S : A N A G E N D A F O R Q U A L I T Y I M P R OV E M E N T
              | or his own understanding to the language used and emphases placed by
              | students.
              | Constructs used to evaluate quality in higher education therefore need
              | to capture the realities separately for students and lecturers. If these
              | constructs are to be of real beneﬁt, they must be understood and interpreted
              | by those responsible for improving quality in relation to the norms and
              | values of those who generated them. Therefore, a process leading to an
              | informed evaluation of quality should enable students and lecturers to make
              | explicit, independently, their own ideas of those characteristics of teaching
              | and learning that are important. Furthermore, students and lecturers need
              | to be able to highlight, deﬁne and record independently any gaps between
              | their perceptions and expectations. Finally, those responsible for improving
              | quality have to be able to gain a critical understanding of both students’
              | and lecturers’ perceptions and expectations of the important constructs and
              | any gaps between them.
              | The Template Process
              | Staughton and Williams’ (1994) Service Template offers one approach to
              | address such concerns. This was developed to illustrate the ‘ﬁt’ between the
              | service provided and that service’s users’ needs. The approach acknow-
              | ledged the uniqueness of each speciﬁc service, allowing those constructs
              | (characteristics) that users believed were important to be deﬁned and gaps
              | between perceptions and expectations to be highlighted and recorded
              | visually. Each characteristic was deﬁned by service users in terminology
              | speciﬁc to the service. As part of this, users speciﬁed positive and negative
              | descriptors for the extremes of a continuum for each characteristic. For
              | example, the characteristic ‘staff appearance’ has been deﬁned through the
              | extremes of ‘smart’ and ‘scruffy’. Subsequently, these users’ perceptions and
              | expectations for each characteristic were located upon its continuum, gaps
              | between perceptions and expectations highlighting where action might be
              | needed. However, by focusing on users, deliverers’ perceptions and expec-
              | tations were excluded, thereby not reﬂecting the dyadic nature of such
              | relationships.
              | Subsequent development of the Service Template Process (Williams et al.,
              | 1999) partially addressed this shortcoming. Users and deliverers were
              | selected using purposive samples based upon cases that were critical to the
              | service, their quality perceptions and expectations being captured separately.
              | Each resulting Service Template therefore reﬂected the language, terminol-
              | ogy and priorities speciﬁc to either service users or deliverers. However,
              | there was still a need to develop the process to enable those charged with
              | improving quality to take ownership of the evaluation ﬁndings.
meta          | 63
text          | 06 ALH 049944 (to/d) 3/2/05 2:06 pm Page 64
              | A C T I V E L E A R N I N G I N H I G H E R E D U C A T I O N 6(1)
              | Organizational development research, and in particular that by Schein
              | (1999), highlights the importance of problem ownership for those
              | developing meaningful solutions. Schein also emphasizes the signiﬁcance
              | of process, often managed by a facilitator, to enable insights by all those
              | involved. Thus, using a development of the Service Template Process within
              | a process consultation framework might allow users and deliverers to work
              | together to improve quality by jointly developing an agenda for action.
              | Through a series of process consultations with seven UK based organiz-
              | ations, drawn from public and private sectors, the process was revised and
              | extended to enable this (Saunders and Williams, 2001). The resultant
              | Template Process is structured around three phases:
              | Phase I: Sample selection
              | Purposive samples are drawn from both students (users) and lecturers
              | (deliverers), focusing upon obtaining critical cases from which logical
              | generalizations may be made regarding the key themes. Thus, whilst the
              | samples are not statistically representative, they capture the diversity and
              | key dimensions of the service.
              | Phase II: Template generation and validation
              | Separate meetings, approximately two hours long, are held by a facilitator
              | for between six and ten students and lecturers. Each meeting follows a
              | process derived from the four stages of the Service Template Process
              | (Williams et al., 1999):
              | Stage 1: Preparation The purpose and nature of the process is
              | explained and meanings of terms clariﬁed. The situation to be considered,
              | for example dissertation supervision, is displayed prominently and referred
              | to regularly to help maintain focus.
              | Stage 2: Explore service characteristics The characteristics of this
              | situation are elicited and recorded in the order they emerge using the partici-
              | pants’ words through a brainstorming type process. Clariﬁcation of meanings
              | is sought; thereby helping ensure everyone in a meeting is using a similar
              | frame of reference and has the same understanding. Subsequently, the list of
              | characteristics is reﬁned and descriptors generated for the extremes of each.
              | For these, participants are asked to suggest the ‘ideal’ situation and the ‘worst’
              | case, the resulting bi-polar rating scales deﬁning these extremes.
              | Stage 3: Plot perceptions and expectations against identiﬁed
              | characteristics A visual representation (template) is built by record-
              | ing ﬁrst the expectations and then the perceptions for each characteristic
meta          | 64
text          | 06 ALH 049944 (to/d) 3/2/05 2:06 pm Page 65
              | S AU N D E R S & W I L L I A M S : A N A G E N D A F O R Q U A L I T Y I M P R OV E M E N T
              | relative to the extremes on a 10-point scale (see Figures 1 and 2). For each
              | characteristic, perceptions are deﬁned through answers to the question
              | ‘What do you perceive to be the position today?’ and expectations through
              | ‘What could reasonably be expected?’ The resultant Template contains typi-
              | cally between 20 and 30 characteristics.
              | Stage 4: Interpret and validate issues Each completed template is
              | discussed with those generating it. This helps conﬁrm the internal validity
              | of the template and those characteristics important in determining quality
              | have been captured. Finally, participants are asked to score those character-
              | istics they consider most important by allocating 100 points between them.
              | Phase III: Exploration, learning and possible action
              | Phase III draws upon Schein’s (1999) ideas about process consultation. The
              | templates are used as catalysts for the students and lecturers involved to gain
              | insights into each other’s perceptions and expectations, at a facilitated
              | meeting. For this to be successful, there must be sufﬁcient time for
              | meaningful discussion and reﬂection. Facilitation needs to enable open,
              | non-judgemental discussion between participants as they understand each
              | other’s templates and generate possible agendas for action. The event has
              | three stages:
              | Stage 1: Brief participants, surface concerns and re-familiarize
              | Participants are reminded of the process to date. The purpose of this two-
              | hour meeting, to share explore, learn and identify possible actions, is
              | restated.
              | Stage 2: Explore and learn This takes the form of dialogue between
              | students and lecturers using their templates as catalysts. It focuses upon
              | jointly establishing and understanding which characteristics are important
              | for quality and why. The joint nature of the process helps reduce problems
              | of second order interpretation, as participants who generated the templates
              | undertake the exploration.
              | Stage 3: Generate possible agendas for action Participants are
              | asked to reﬂect on the meeting and focus upon actions needed to improve
              | quality. Through this an agenda of items requiring action is identiﬁed and
              | owned by the students and lecturers.
              | The application and utility of the Template Process to the evaluation and
              | review of modules is illustrated now using an evaluation of dissertation
              | supervision in a new university business school. Within this university,
              | students’ evaluations are a recognised component of quality assurance,
meta          | 65
text          | 06 ALH 049944 (to/d) 3/2/05 2:06 pm Page 66
              | ACTIVE LEARNING IN HIGHER EDUCATION 6(1)
              | !
              | -
              | , " + 45 ’ "(
              | " " " ( " 01 1 3 %
              | +
              | (
meta          | 66
text          | "
              | " (
              | "
              | "
              | "
              | "
              | (
              | (
              | %
              | $
              | $ ) )
              | 2 2
              | +
              | " 2
              | /
              | /
              | "
              | +
              | ’
meta          | 1
text          | %
meta          | 2
text          | (
meta          | 0
text          | ’ +" +" + 0 ’
              | " " &
              | * . . . & & 6 6
              | e
              | r
              | " " u
              | " . . ! ig
              | ’
              | s
              | s
              | e
              | c
              | o
              | r
              | p
              | y
              | r
              | o
              | s
              | i
              | v
              | r
              | e
              | p
              | u
              | s
              | n
              | o
              | i
              | t
              | a
              | t
              | r
              | e
              | s
              | s
              | i
              | d
              | e
              | h
              | t
              | ‘
              | f
              | o
              | s
              | n
              | o
              | i
              | t
              | a
              | t
              | c
              | e
              | p
              | x
              | e
              | d
              | n
              | a
              | e
              | t
              | a
              | l
              | p
              | m
              | e
              | T
meta          | 1
text          | F
              | s
              | n
              | o
              | i
              | t
              | " p
              | ! e
              | c
              | $ r
              | e
              | p
              | ’
              | s
              | t
              | n
              | e
              | d
              | u
              | t
              | s
              | % g
              | $ n
              | # i
              | t
              | c
              | e
              | ﬂ
              | e
              | r
              | 06 ALH 049944 (to/d) 3/2/05 2:06 pm Page 67
              | S AU N D E R S & W I L L I A M S : A N A G E N D A F O R Q U A L I T Y I M P R OV E M E N T
              | !
              | ,
              | ’
              | "
              | &
              | %
              | ’
              | -
              | -
              | -
              | *
              | ) ,
              | ( +
              | # ’
              | +
              | . .
              | &
              | "
              | !
              | $
              | %
              | $
              | #
              | "
              | !
              | ’
              | s
              | s
              | e
              | c
              | o
              | r
              | p
              | y
              | r
              | o
              | s
              | i
              | v
              | r
              | e
              | p
              | u
              | s
              | n
              | o
              | i
              | t
              | a
              | t
              | r
              | e
              | s
              | s
              | i
              | d
              | e
              | h
              | t
              | ‘
              | f
              | o
              | s
              | n
              | o
              | i
              | t
              | a
              | t
              | c
              | e
              | p
              | x
              | e
              | d
              | n
              | a
              | s
              | n
              | o
              | i
              | t
              | p
              | e
              | c
              | r
              | e
              | p
              | ’
              | s
              | r
              | o
              | s
              | i
              | v
              | r
              | e
              | p
              | u
              | s
              | g
              | n
              | i
              | t
              | c
              | e
              | ﬂ
              | e
              | r
              | e
              | t
              | a
              | l
              | p
              | m
              | e
              | T
meta          | 2
text          | e
              | r
              | u
              | g
              | i
              | F
meta          | 67
text          | 06 ALH 049944 (to/d) 3/2/05 2:06 pm Page 68
              | A C T I V E L E A R N I N G I N H I G H E R E D U C A T I O N 6(1)
              | questionnaires being used systematically to collect feedback for review
              | purposes.
              | Using the Template Process
              | The dissertation module operating within this business school has, since
              | the mid-1990s, doubled in size to over 300 students along with a corre-
              | sponding growth in supervisor numbers. Each student attends six research
              | methods workshops, delivered at the start of level III and is allocated a
              | supervisor, who provides one-to-one support. A growing number of
              | comments from students regarding the nature and quality of supervision
              | received suggested there were associated issues that had not been
              | identified in the end-of-module evaluation questionnaire. This, combined
              | with the rapid growth led the module tutor to undertake a full review of
              | the dissertation module and its operation. In discussion with the module
              | tutor, it was agreed that we would act as facilitators using the Template
              | Process to review dissertation supervision. Through this, we aimed to
              | capture students’ and supervisors’ expectations and perceptions of the
              | dissertation supervision process and their suggestions for possible
              | actions.
              | Two purposive samples were selected to represent student and supervisor
              | views. The eight students taking the level III dissertation module
              | represented all degree combinations within the business school, whilst the
              | six supervisors encompassed a wide range of supervisory and subject
              | experience. For both samples, perceptions and expectations of the quality
              | of the supervisory process were established and recorded separately. This
              | resulted in two templates, one illustrating the students’ and the other the
              | supervisors’ perceptions and expectations. Some of the characteristics
              | captured by the students’ template included ‘Advice’, ‘Feedback’, ‘Relation-
              | ship – trust’ and ‘Information – quality’ (see Figure 1) were not captured
              | in the same words in the supervisors’ template (see Figure 2). Conversely,
              | characteristics in the supervisors’ template, such as ‘Student motivation’,
              | did not appear in the students’ template.
              | Both perceptions and expectations were recorded against the 10-point
              | scale. Consistency of interpretation of the scales was explored as the percep-
              | tions and expectations for each characteristic were plotted, as well as during
              | interpretation and validation. Within each meeting, differences between
              | individuals’ scores for perceived and expected performance were recorded
              | for each characteristic. These were represented by the length of the
              | perceived performance and expected performance bars. For example, there
              | was considerably more variation in students’ perceptions of the ‘Availability
              | of tutor’ than in their expectations (Figure 1). The gap between students’
meta          | 68
text          | 06 ALH 049944 (to/d) 3/2/05 2:06 pm Page 69
              | S AU N D E R S & W I L L I A M S : A N A G E N D A F O R Q U A L I T Y I M P R OV E M E N T
              | expectation that the research methods ‘Workshops time’ should ‘reﬂect
              | dissertation progress/ongoing’ and their perception that they were ‘lumped
              | together’ emphasized the actual gap between their perceptions and expec-
              | tations (Figure 1). The scores revealed those characteristics considered most
              | important by students (‘Advice’, ‘Feedback’ and ‘Relationship-trust’) and
              | supervisors (‘Assessment criteria clarity’, ‘Student’s commitment to topic’
              | and ‘Student’s attitude/preparedness’).
              | Subsequently, all involved explored the templates jointly. This enabled the
              | students and supervisors to begin to develop a shared understanding of the
              | range of views. Discussion was introduced by a short presentation from
              | students and supervisors explaining their own templates and the high-
              | scoring characteristics. Each participant was provided with copies of both
              | templates and necessary clariﬁcations sought. Following the presentations,
              | these students and supervisors chose to discuss and explore the supervision
              | process collectively, focusing on the major differences and similarities of
              | the high scoring characteristics and the gaps between perceptions and
              | expectations (Figures 1 and 2).
              | There were clear concerns for both students and supervisors. Students
              | highlighted the consistency of the supervisory process. This is apparent in
              | the relatively high score (25) of the characteristic ‘Advice’ as well as the
              | wide range of perceptions for many other characteristics (Figure 1). The
              | ideal for ‘Advice’ was ‘consistent level playing ﬁeld’, and these terms were
              | repeated frequently throughout the discussion. Concerns of supervisors
              | centred upon assessment criteria; apparent in the characteristics: ‘Assess-
              | ment criteria – clarity’ and ‘Assessment criteria – objective measurement’
              | (Figure 2). For both, the relatively wide range of perceptions suggested
              | differences in views. Subsequent discussion highlighted further differences.
              | Whereas supervisors indicated that support might not reasonably be
              | ‘readily available’, their perceptions emphasized wide variation in practice
              | (Figure 2). In contrast, students expected support should ‘reﬂect individual
              | student need’ and ‘sufﬁcient “quality time”’ should be available, whilst
              | perceiving wide variations in practice (Figure 1).
              | As part of the meeting we asked student and supervisors to record the
              | ‘main messages’ from the templates and suggest ‘actions that would really
              | make a difference’. This resulted in, for example, an agreement to resched-
              | ule research methods workshops to reﬂect more closely the stages students
              | should have reached in their dissertations. Supervisors agreed to explore
              | issues of consistency of advice at a subsequent staff development session.
              | This highlighted that there was more agreement regarding the nature of the
              | dissertation than supervisors had assumed and that the discussion was
              | helpful in developing a common understanding. However, further work
              | was needed on consistency of advice, in particular the amount of help that
meta          | 69
text          | 06 ALH 049944 (to/d) 3/2/05 2:06 pm Page 70
              | A C T I V E L E A R N I N G I N H I G H E R E D U C A T I O N 6(1)
              | should reasonably be given to students. A working group considered this
              | subsequently.
              | Discussion
              | The Template Process allowed students and lecturers to generate indepen-
              | dently those characteristics they believed were important to a deﬁned
              | teaching and learning situation. Subsequently, gaps between perceptions
              | and expectations for each characteristic were tested and recorded. The
              | process therefore offers a method for establishing valid information
              | considered important, rather than reﬂecting the assumptions and values of
              | the evaluation instrument designer. Despite an apparent lack of common-
              | ality in the language used by students and lecturers, there were often
              | elements of common ground in the important characteristics. Where this
              | was not the case, it emphasized that students and lecturers were operating
              | within differing assumptions and norms. The Template Process therefore
              | enables issues to be surfaced that may challenge the established modes of
              | teaching and learning.
              | These observations reinforce the use of the Template Process within a
              | process consultation framework, the facilitator acting as guardian of the
              | process. Her or his role is to ensure that both students and lecturers
              | contribute fully to template generation and validation (Phase II). During
              | the subsequent exploration, learning and possible action (Phase III), the
              | facilitator helps focus dialogue on both learning and action. She or he must
              | therefore be able to listen to individuals’ contributions, summarize alterna-
              | tive views and judge when to move the process towards identifying possible
              | actions. Colleagues who have undertaken this role have commented that the
              | skills required are similar to those they use when leading seminar groups.
              | However, the requirement for the facilitator to be, and to be seen to be,
              | neutral means that she or he is unlikely to be part of the module team.
              | The advantages of the Template Process appear to be greatest for modules
              | where problems or issues related to quality are evident but deﬁned poorly.
              | In such instances the process allows students and lecturers to deﬁne the
              | issue independently in their own words. Visual representation of the data
              | facilitates confrontative intervention as students and lecturers explore each
              | other’s views (Phase III). By doing this jointly, differences and similarities
              | in the norms and values upon which these ideas are based are highlighted
              | leading to new mutual understandings speciﬁc to that situation. Participant
              | interpretation and dialogue help maintain data integrity and ensure that the
              | level and nature of detail available is sufﬁcient upon which to act. The
              | discursive nature of this phase also allows different views to be discussed,
              | understood and recognized within the speciﬁed context.
meta          | 70
text          | 06 ALH 049944 (to/d) 3/2/05 2:06 pm Page 71
              | S AU N D E R S & W I L L I A M S : A N A G E N D A F O R Q U A L I T Y I M P R OV E M E N T
              | The Template Process is, compared to traditional means of evaluating
              | quality, time consuming for both the students and the lecturers involved.
              | For this reason it has been used only on a maximum of one module per
              | year group for a course, either as an integral part of teaching (for example
              | in modules on research methods or managing service operations), where
              | there appears to be an issue or problem that is poorly deﬁned, or in the
              | context of a more major review. Subsequently, the characteristics identiﬁed
              | as important have been incorporated in more traditional evaluation
              | methods. We have found that students enjoy the interactive aspects of
              | developing their templates and subsequently working with lecturers to
              | develop possible actions to improve quality. The majority have commented
              | that they found the process engaging and that, unlike more traditional
              | methods of evaluation, their contributions were really valued. In addition,
              | by introducing variety to the methods of evaluation used across a course,
              | student fatigue with more traditional approaches appears to be reduced.
              | In conclusion, the Template Process reﬂects the reality of a dyadic inter-
              | change between students and lecturers in teaching and learning. It is not
              | intended to provide a statistically representative evaluation. Rather, it offers
              | an additional tool to the range of existing quality assessment processes. The
              | process enables students and lecturers to test their assumptions about an
              | existing module independently prior to developing a common understand-
              | ing of any problems or issues and possible actions. Because predetermined
              | scales are not used, the process is applicable without modiﬁcation to evalu-
              | ating quality across a range of teaching and learning situations. The facilita-
              | tor’s role is to assist in the derivation, exploration and subsequent dialogue
              | about the templates and agreement of possible courses of action. The process
              | therefore offers an additional tool that, although time-consuming for those
              | involved, captures the data in a systematic manner. Integral to the process is
              | the need for discussion, understanding and learning about problems and
              | issues and taking ownership of agreed solutions – aspects whose importance
              | has been highlighted in the maintenance and enhancement of quality.
              | References
ref           | B I N G H A M , R . & OT T E W I L L , R . (2001) ‘Whatever Happened to Peer Review?
              | Revitalising the Contribution of Tutors to Course Evaluation’, Quality Assurance in
              | Education 9(1): 32–9.
              | C A R M E N, J. M . (1990) ‘Consumer Perceptions of Service Quality: An Assessment of
              | the SERVQUAL Dimensions’, Journal of Retailing 66(1): 33–5.
              | C H A P P L E , M . & M U R P H Y, R . (1996) ‘The Nominal Group Technique: Extending the
              | Evaluation of Students’ Teaching and Learning Experiences’, Assessment and Evaluation
              | in Higher Education 21(2):147–59.
              | C RO N I N, J. J. & TAY L O R , S . A . (1992) ‘Measuring Service Quality: A
              | Re-examination and Extension’, Journal of Marketing 56 (July): 56–68.
meta          | 71
text          | 06 ALH 049944 (to/d)
              | 3/2/05
              | 2:06 pm
              | Page 72
              | A C T I V E L E A R N I N G I N H I G H E R E D U C A T I O N 6(1)
ref           | C U T H B E RT, P. F. (1996) ‘Managing Service Quality in HE: Is SERVQUAL the Answer?
              | Part 2’, Managing Service Quality 6(3): 31–5.
              | H A RV E Y, L . (1998) ‘An Assessment of Past and Current Approaches to Quality in
              | Higher Education’, Australian Journal of Education 42(3): 237–55.
              | H E N D RY, G. D. , C U M M I N G, R . G. , LYO N, P. M . & G O R D O N, J. (2001)
              | ‘Student-centred Course Evaluation in a Four-year, Problem Based Medical
              | Programme: Issues in Collection and Management of Feedback’, Assessment and
              | Evaluation in Higher Education 26(4): 327–39.
              | N A R A S I M H A N, K . (1997) ‘Improving Teaching and Learning: The Perceptions Minus
              | Expectations Gap Analysis Approach’, Training for Quality 5(3): 121–25.
              | PA R A S U R A M A N, A . (1995) ‘Measuring and Monitoring Service Quality’, in
              | W. J. Glynn and J. G. Barnes (eds) Understanding Services Management, pp. 143–177.
              | Chichester: Wiley.
              | PA R A S U R A M A N, A . , Z E I T H A M L , V. A . & B E R RY, L . L . (1985) ‘A Conceptual Model
              | of Service Quality and Its Implications for Future Research’, Journal of Marketing
              | 49(Fall): 41–50.
              | PA R A S U R A M A N, A . , Z E I T H A M L , V. A . & B E R RY, L . L . (1991) ‘SERVQUAL: A
              | Multiple-item Scale for Measuring Consumer Perception of Service Quality’, Journal
              | of Retailing 64(Spring): 12–40.
              | RO S E N, D. E . & S U P R E N A N T, C . (1998) ‘Evaluating Relationships: Are Satisfaction
              | and Quality Enough?’, International Journal of Service Industry Management 9(2): 103–25.
              | S AU N D E R S , M . N. K . & W I L L I A M S , C . S . (2001) ‘Double Loop Learning and
              | Improving Organisational Relationships: The Application of the Template Process’,
              | in M. A. Rahim, R. T. Golembiewski and C. Lundberg (eds) Current Topics in
              | Management Vol. 6, pp. 127–148. Location: Elsevier Science.
              | S C H E I N, E . H . (1999) Process Consultation Revisited: Building the Helping Relationship. Reading,
              | MA: Addison-Wesley Longman.
              | S TAU G H T O N, R . V. W. & W I L L I A M S , C . S . (1994) ‘Towards a Simple, Visual
              | Representation of Fit in Service Organisations: The Contribution of the Service
              | Template’, International Journal of Operations and Production Management 14(5): 76–85.
              | W I L L I A M S , C . S . , S AU N D E R S , M . N. K . & S TAU G H T O N, R . V. W. (1999)
              | ‘Understanding Service Quality in the New Public Sector: An Exploration of
              | Relationships in the Process of Funding Social Housing’, International Journal of Public
              | Sector Management 12(4): 366–79.
text          | Biographical notes
              | M A R K N. K . S AU N D E R S is Head of Research and Reader in Research Methods at
              | Oxford Brookes University Business School.
              | Address: The Business School, Oxford Brookes University, Wheatley Campus, Wheatley,
              | Oxford OX33 1HX, UK. [email: mnksaunders@brookes.ac.uk]
              | C H R I S T I N E S . W I L L I A M S is Head of the Department of Marketing and Strategy at the
              | University of Gloucestershire Business School.
              | Address: The Business School, University of Gloucestershire, The Park, Cheltenham
              | GL50 2QF, UK. [email: cwilliams@glos.ac.uk]
meta          | 72